{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2c8ddd3-9ec8-4c78-9d88-d677636ac5b5",
   "metadata": {},
   "source": [
    "# Record Linkage\n",
    "Record linkage is a powerful technique used to merge multiple datasets together, used when values have typos or different spellings. In this chapter, you'll learn how to link records by calculating the similarity between strings—you’ll then use your new skills to join two restaurant review datasets into one clean master dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e40c536-38cb-4938-9ec5-912a7ce267af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import recordlinkage\n",
    "\n",
    "restaurants = pd.read_csv('D:/Development/DataCamp/Data Science with Python - Career Track/12. Cleaning Data in Python/datasets/restaurants_L2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1af59f1a-b2df-4b88-ab6f-977d9eb01cb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>name</th>\n",
       "      <th>addr</th>\n",
       "      <th>city</th>\n",
       "      <th>phone</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>arnie morton's of chicago</td>\n",
       "      <td>435 s. la cienega blv .</td>\n",
       "      <td>los angeles</td>\n",
       "      <td>3102461501</td>\n",
       "      <td>american</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>art's delicatessen</td>\n",
       "      <td>12224 ventura blvd.</td>\n",
       "      <td>studio city</td>\n",
       "      <td>8187621221</td>\n",
       "      <td>american</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>campanile</td>\n",
       "      <td>624 s. la brea ave.</td>\n",
       "      <td>los angeles</td>\n",
       "      <td>2139381447</td>\n",
       "      <td>american</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>fenix</td>\n",
       "      <td>8358 sunset blvd. west</td>\n",
       "      <td>hollywood</td>\n",
       "      <td>2138486677</td>\n",
       "      <td>american</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>grill on the alley</td>\n",
       "      <td>9560 dayton way</td>\n",
       "      <td>los angeles</td>\n",
       "      <td>3102760615</td>\n",
       "      <td>american</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                       name                       addr  \\\n",
       "0           0  arnie morton's of chicago   435 s. la cienega blv .    \n",
       "1           1         art's delicatessen       12224 ventura blvd.    \n",
       "2           2                  campanile       624 s. la brea ave.    \n",
       "3           3                      fenix    8358 sunset blvd. west    \n",
       "4           4         grill on the alley           9560 dayton way    \n",
       "\n",
       "          city       phone      type  \n",
       "0  los angeles  3102461501  american  \n",
       "1  studio city  8187621221  american  \n",
       "2  los angeles  2139381447  american  \n",
       "3    hollywood  2138486677  american  \n",
       "4  los angeles  3102760615  american  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "restaurants.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b73e21f-c75c-4356-847a-e1ef63894335",
   "metadata": {},
   "source": [
    "### 1. The Cutoff Point\n",
    "\n",
    " In this exercise, and throughout this chapter, you'll be working with the restaurants DataFrame which has data on various restaurants. Your ultimate goal is to create a restaurant recommendation engine, but you need to first clean your data.\n",
    "\n",
    " This version of restaurants has been collected from many sources, where the cuisine_type column is riddled with typos, and should contain only italian, american and asian cuisine types. There are so many unique categories that remapping them manually isn't scalable, and it's best to use string similarity instead.\n",
    "\n",
    " Before doing so, you want to establish the cutoff point for the similarity score using the fuzzywuzzy's process.extract() function by finding the similarity score of the most distant typo of each category.\n",
    " \n",
    " Instructions:\n",
    " 1. Import process from fuzzywuzzy. Store the unique cuisine_types into unique_types. Calculate the similarity of 'asian', 'american', and 'italian' to all possible cuisine_types using process.extract(), while returning all possible matches.\n",
    " 2. Take a look at the output, what do you think should be the similarity cutoff point when remapping categories?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc6342e9-6eb8-40eb-8ae7-33192ab3f27c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('asian', 100), ('italian', 67), ('american', 62), ('mexican', 50), ('cajun', 40), ('southwestern', 36), ('southern', 31), ('coffeebar', 26), ('steakhouses', 25)]\n",
      "[('american', 100), ('mexican', 80), ('cajun', 68), ('asian', 62), ('italian', 53), ('southwestern', 41), ('southern', 38), ('coffeebar', 24), ('steakhouses', 21)]\n",
      "[('italian', 100), ('asian', 67), ('mexican', 43), ('american', 40), ('cajun', 33), ('southern', 27), ('southwestern', 26), ('steakhouses', 26), ('coffeebar', 12)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Programs\\anaconda3\\lib\\site-packages\\fuzzywuzzy\\fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "# 1.\n",
    "# Import process from fuzzywuzzy\n",
    "from fuzzywuzzy import process\n",
    "\n",
    "# Store the unique values of cuisine_type in unique_types\n",
    "unique_types = restaurants['type'].unique() # cuisine_type\n",
    "\n",
    "# Calculate similarity of 'asian' to all values of unique_types\n",
    "print(process.extract('asian', unique_types, limit = len(unique_types)))\n",
    "\n",
    "# Calculate similarity of 'american' to all values of unique_types\n",
    "print(process.extract('american', unique_types, limit = len(unique_types)))\n",
    "\n",
    "# Calculate similarity of 'italian' to all values of unique_types\n",
    "print(process.extract('italian', unique_types, limit = len(unique_types)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43ff223-4fdd-4631-adf6-43903b515e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.\n",
    "# Question\n",
    "# Take a look at the output, what do you think should be the similarity cutoff point when remapping categories?\n",
    "\n",
    "# Answer\n",
    "# 80\n",
    "# Correct! 80 is that sweet spot where you convert all incorrect typos without remapping incorrect categories. Often times though, you may need to combine the techniques learned in chapter 2, especially since there could be strings that make it beyond our cutoff point, but are not actually a match!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83b13c6-9c36-4af0-9868-8b77f98af210",
   "metadata": {},
   "source": [
    "### 2. Remapping Categories II\n",
    "\n",
    " In the last exercise, you determined that the distance cutoff point for remapping typos of 'american', 'asian', and 'italian' cuisine types stored in the cuisine_type column should be 80.\n",
    "\n",
    " In this exercise, you're going to put it all together by finding matches with similarity scores equal to or higher than 80 by using fuzywuzzy.process's extract() function, for each correct cuisine type, and replacing these matches with it. Remember, when comparing a string with an array of strings using process.extract(), the output is a list of tuples where each is formatted like:\n",
    "\n",
    " `(closest match, similarity score, index of match)`\n",
    "\n",
    " The restaurants DataFrame is in your environment, and you have access to a categories list containing the correct cuisine types ('italian', 'asian', and 'american').\n",
    " \n",
    " Instructions:\n",
    " 1. Return all of the unique values in the cuisine_type column of restaurants.\n",
    " 2. Okay! Looks like you will need to use some string matching to correct these misspellings! As a first step, create a list of all possible matches, comparing 'italian' with the restaurant types listed in the cuisine_type column.\n",
    " 3. Now you're getting somewhere! Now you can iterate through matches to reassign similar entries. Within the for loop, use an if statement to check whether the similarity score in each match is greater than or equal to 80. If it is, use .loc to select rows where cuisine_type in restaurants is equal to the current match (which is the first element of match), and reassign them to be 'italian'.\n",
    " 4. Finally, you'll adapt your code to work with every restaurant type in categories. Using the variable cuisine to iterate through categories, embed your code from the previous step in an outer for loop. Inspect the final result. This has been done for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1be317f9-024f-4888-9d0f-6797e60e266d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['american' 'asian' 'italian' 'coffeebar' 'mexican' 'southwestern'\n",
      " 'steakhouses' 'southern' 'cajun']\n"
     ]
    }
   ],
   "source": [
    "# 1.\n",
    "# Inspect the unique values of the cuisine_type column\n",
    "print(restaurants['type'].unique()) # cuisine_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12b85a66-d73b-4f59-a3c7-ef2925f713e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('italian', 100, 6), ('italian', 100, 10), ('italian', 100, 11), ('italian', 100, 16), ('italian', 100, 19)]\n"
     ]
    }
   ],
   "source": [
    "# 2. \n",
    "# Create a list of matches, comparing 'italian' with the cuisine_type column\n",
    "matches = process.extract('italian', restaurants['type'], limit=len(restaurants['type'])) # type\n",
    "\n",
    "# Inspect the first 5 matches\n",
    "print(matches[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2ac1810-e631-4182-b672-991d46ca4bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.\n",
    "# Create a list of matches, comparing 'italian' with the cuisine_type column\n",
    "matches = process.extract('italian', restaurants['type'], limit=len(restaurants.type)) # # type\n",
    "\n",
    "# Iterate through the list of matches to italian\n",
    "for match in matches:\n",
    "  # Check whether the similarity score is greater than or equal to 80\n",
    "  if match[1] >= 80:\n",
    "    # Select all rows where the cuisine_type is spelled this way, and set them to the correct cuisine\n",
    "    restaurants.loc[restaurants['type'] == match[0]] = 'italian' # # type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73e9d05-a9e1-4b33-95ff-41596a273f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. \n",
    "# Iterate through categories\n",
    "for cuisine in categories:  \n",
    "  # Create a list of matches, comparing cuisine with the cuisine_type column\n",
    "  matches = process.extract(cuisine, restaurants['cuisine_type'], limit=len(restaurants.cuisine_type))\n",
    "\n",
    "  # Iterate through the list of matches\n",
    "  for match in matches:\n",
    "     # Check whether the similarity score is greater than or equal to 80\n",
    "    if match[1] >= 80:\n",
    "      # If it is, select all rows where the cuisine_type is spelled this way, and set them to the correct cuisine\n",
    "      restaurants.loc[restaurants['cuisine_type'] == match[0]] = cuisine\n",
    "      \n",
    "# Inspect the final result\n",
    "print(restaurants['cuisine_type'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2cd77d-a96c-43dd-95fd-766793cb2580",
   "metadata": {},
   "source": [
    "### 3. Pairs of Restaurants\n",
    "\n",
    " In the last lesson, you cleaned the restaurants dataset to make it ready for building a restaurants recommendation engine. You have a new DataFrame named restaurants_new with new restaurants to train your model on, that's been scraped from a new data source.\n",
    "\n",
    " You've already cleaned the cuisine_type and city columns using the techniques learned throughout the course. However you saw duplicates with typos in restaurants names that require record linkage instead of joins with restaurants.\n",
    "\n",
    " In this exercise, you will perform the first step in record linkage and generate possible pairs of rows between restaurants and restaurants_new. Both DataFrames, pandas and recordlinkage are in your environment.\n",
    " \n",
    " Instructions:\n",
    " 1. Instantiate an indexing object by using the Index() function from recordlinkage. Block your pairing on cuisine_type by using indexer's' .block() method. Generate pairs by indexing restaurants and restaurants_new in that order.\n",
    " 2. Now that you've generated your pairs, you've achieved the first step of record linkage. What are the steps remaining to link both restaurants DataFrames, and in what order?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403d5054-2de0-46c4-ad40-37273fbc5044",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.\n",
    "# Create an indexer and object and find possible pairs\n",
    "indexer = recordlinkage.Index()\n",
    "\n",
    "# Block pairing on cuisine_type\n",
    "indexer.block('cuisine_type') \n",
    "\n",
    "# Generate pairs\n",
    "pairs = indexer.index(restaurants, restaurants_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1db0dc-24a3-4a61-9ace-ad68a31e8ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. \n",
    "# Question\n",
    "# Now that you've generated your pairs, you've achieved the first step of record linkage. What are the steps remaining to link both restaurants DataFrames, and in what order?\n",
    "\n",
    "# Answer\n",
    "# Compare between columns, score the comparison, then link the DataFrames."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f6c7de-175f-4591-894f-378cbccf26a8",
   "metadata": {},
   "source": [
    "### 4. Similiar Restaurants\n",
    "\n",
    " In the last exercise, you generated pairs between restaurants and restaurants_new in an effort to cleanly merge both DataFrames using record linkage.\n",
    "\n",
    " When performing record linkage, there are different types of matching you can perform between different columns of your DataFrames, including exact matches, string similarities, and more.\n",
    "\n",
    " Now that your pairs have been generated and stored in pairs, you will find exact matches in the city and cuisine_type columns between each pair, and similar strings for each pair in the rest_name column. Both DataFrames, pandas and recordlinkage are in your environment.\n",
    " \n",
    " Instructions:\n",
    " 1. Instantiate a comparison object using the recordlinkage.Compare() function.\n",
    " 2. Use the appropriate comp_cl method to find exact matches between the city and cuisine_type columns of both DataFrames. Use the appropriate comp_cl method to find similar strings with a 0.8 similarity threshold in the rest_name column of both DataFrames.\n",
    " 3. Compute the comparison of the pairs by using the .compute() method of comp_cl.\n",
    " 4. Print out potential_matches, the columns are the columns being compared, with values being 1 for a match, and 0 for not a match for each pair of rows in your DataFrames. To find potential matches, you need to find rows with more than matching value in a column. You can find them with `potential_matches[potential_matches.sum(axis = 1) >= n]` Where n is the minimum number of columns you want matching to ensure a proper duplicate find, what do you think should the value of n be?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd72fa6-e91f-4e15-b743-68aab4bf2f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.\n",
    "# Create a comparison object\n",
    "comp_cl = recordlinkage.Compare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec147fb7-3e07-4816-9ae4-314d4b0da821",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.\n",
    "# Create a comparison object\n",
    "comp_cl = recordlinkage.Compare()\n",
    "\n",
    "# Find exact matches on city, cuisine_types \n",
    "comp_cl.exact('city', 'city', label='city')\n",
    "comp_cl.exact('cuisine_type', 'cuisine_type', label = 'cuisine_type')\n",
    "\n",
    "# Find similar matches of rest_name\n",
    "comp_cl.string('rest_name', 'rest_name', label='name', threshold = 0.8) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5f590f-04a6-4331-b135-c65ecdd0489f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.\n",
    "# Create a comparison object\n",
    "comp_cl = recordlinkage.Compare()\n",
    "\n",
    "# Find exact matches on city, cuisine_types - \n",
    "comp_cl.exact('city', 'city', label='city')\n",
    "comp_cl.exact('cuisine_type', 'cuisine_type', label='cuisine_type')\n",
    "\n",
    "# Find similar matches of rest_name\n",
    "comp_cl.string('rest_name', 'rest_name', label='name', threshold = 0.8) \n",
    "\n",
    "# Get potential matches and print\n",
    "potential_matches = comp_cl.compute(pairs, restaurants, restaurants_new)\n",
    "print(potential_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ea63ed-e1a1-4254-ab5a-c8e064ab8ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. \n",
    "# Question\n",
    "# Print out potential_matches, the columns are the columns being compared, with values being 1 for a match, and 0 for not a match for each pair of rows in your DataFrames. To find potential matches, you need to find rows with more than matching value in a column. You can find them with\n",
    "\n",
    "# `potential_matches[potential_matches.sum(axis = 1) >= n]`\n",
    "\n",
    "# Where n is the minimum number of columns you want matching to ensure a proper duplicate find, what do you think should the value of n be?\n",
    "\n",
    "# Answer\n",
    "# 3 because I need to have matches in all my columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38588f66-24ed-4ca9-9e01-07dce0e5595b",
   "metadata": {},
   "source": [
    "### 5. Linking them Together!\n",
    "\n",
    " In the last lesson, you've finished the bulk of the work on your effort to link restaurants and restaurants_new. You've generated the different pairs of potentially matching rows, searched for exact matches between the cuisine_type and city columns, but compared for similar strings in the rest_name column. You stored the DataFrame containing the scores in potential_matches.\n",
    "\n",
    " Now it's finally time to link both DataFrames. You will do so by first extracting all row indices of restaurants_new that are matching across the columns mentioned above from potential_matches. Then you will subset restaurants_new on these indices, then append the non-duplicate values to restaurants. All DataFrames are in your environment, alongside pandas imported as pd.\n",
    " \n",
    " Instructions:\n",
    " - Isolate instances of potential_matches where the row sum is above or equal to 3 by using the .sum() method.\n",
    " - Extract the second column index from matches, which represents row indices of matching record from restaurants_new by using the .get_level_values() method.\n",
    " - Subset restaurants_new for rows that are not in matching_indices.\n",
    " - Append non_dup to restaurants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c38a87-4dd3-4e18-84bb-abd8328c47ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isolate potential matches with row sum >=3\n",
    "matches = potential_matches[potential_matches.sum(axis = 1) >= 3]\n",
    "\n",
    "# Get values of second column index of matches\n",
    "matching_indices = matches.index.get_level_values(1)\n",
    "\n",
    "# Subset restaurants_new based on non-duplicate values\n",
    "non_dup = restaurants_new[~restaurants_new.index.isin(matching_indices)]\n",
    "\n",
    "# Append non_dup to restaurants\n",
    "full_restaurants = restaurants.append(non_dup)\n",
    "print(full_restaurants)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
